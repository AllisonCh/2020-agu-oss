{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing your code\n",
    "_building confidence that it is doing what it is supposed to!_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams[\"font.size\"] = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathematical identities & analytic solutions\n",
    "_We know the answer_\n",
    "\n",
    "For example, for a moving average calculation, we know that if we compute the moving average along a straight line, the average over each segment should be the same as if we evaluate the line at the centre of that segment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'agu_oss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-cb64fe237ea7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0magu_oss\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmoving_average\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'agu_oss'"
     ]
    }
   ],
   "source": [
    "from agu_oss import moving_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line(x, slope=1, intercept=0):\n",
    "    return slope * x + intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_width = 5\n",
    "n = 20\n",
    "x = np.linspace(0, 100, n)\n",
    "y = line(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if np.mod(window_width, 2) == 1:\n",
    "    moving_average_x = x  \n",
    "elif np.mod(window_width, 2) == 0: \n",
    "    # average assigned at the centers\n",
    "    moving_average_x = x - np.diff(x[:2])/2 # assumes evenly spaced x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_average_y = moving_average(y, window_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(x, y, '-o', label=\"original\")\n",
    "ax.plot(moving_average_x, moving_average_y, '-s', label=\"averaged\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = line(moving_average_x)\n",
    "\n",
    "start_ind = window_width // 2\n",
    "end_ind = len(y) - (window_width - start_ind)\n",
    "passed = np.allclose(\n",
    "    moving_average_y[start_ind:end_ind],\n",
    "    y_test[start_ind:end_ind]\n",
    ")\n",
    "assert(passed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code comparisons\n",
    "_Compare against an independent implementation_\n",
    "\n",
    "We can also implement a moving average using pandas. Lets compare with that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"x\": x,\n",
    "    \"y\": y\n",
    "})\n",
    "df.set_index(\"x\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_averaged = df[\"y\"].rolling(window=window_width).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd_averaged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the pandas approach puts the value at the end of the window, whereas our implementation puts it at the center. So we need to account for that in our comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passed_comparison = np.allclose(\n",
    "    pd_averaged.values[window_width-1:-1],\n",
    "    moving_average_y[start_ind:end_ind]\n",
    ")\n",
    "assert(passed_comparison)\n",
    "passed_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Behaviour: Convergence \n",
    "_We expect certain behaviours of the code_\n",
    "\n",
    "Even if we don't know the real solution, we know certain things about how the solution to converge.\n",
    "\n",
    "For example: computing derivatives. Consider the Taylor expansion of a function \n",
    "\n",
    "$$\n",
    "f(x + h) \\simeq f(x) + \\frac{\\partial f(x)}{\\partial x} h + \\mathcal{O}(h^2)\n",
    "$$\n",
    "\n",
    "If we approximate the solution to $f(x + h)$ by $f(x)$, the we expect that as we decrease $h$, then the error $\\varepsilon$ should decrease as $\\mathcal{O}(h)$:\n",
    "\n",
    "$$\n",
    "\\varepsilon(h) = |f(x + h) - f(x)|\n",
    "$$\n",
    "\n",
    "e.g. for small enough $h$, if we decrease $h$ by a factor of 2, $\\varepsilon$ should decrease by a factor of 2. \n",
    "\n",
    "If instead, we include gradient information in our approximation of $f(x + h)$, namely using $f(x) + \\frac{\\partial f(x)}{\\partial x} h$, then as we decrease h, the error $\\hat{\\varepsilon}$ should decrease as $\\mathcal{O}(h)$:\n",
    "\n",
    "$$\n",
    "\\hat{\\varepsilon}(h) = \\left|f(x + h) - \\left(f(x) + \\frac{\\partial f(x)}{\\partial x} h)\\right)\\right|\n",
    "$$\n",
    "\n",
    "e.g. for small enough $h$, if we decrease $h$ by a factor of 2, $\\hat{\\varepsilon}$ should decrease by a factor of 4. \n",
    "\n",
    "#### Why do we care about this behaviour?\n",
    "\n",
    "If we are using gradient-based optimization (e.g. in an inversion or a machine learning application), we need to provide methods for computing derivatives at any point. This test checks the behaviour of the derivative. \n",
    "\n",
    "**For reference:** https://doi.org/10.1137/1.9781611973808"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    \"\"\"\n",
    "    A decaying sinusoid\n",
    "    \"\"\"\n",
    "    return np.exp(-x**2/10) * np.sin(2*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_deriv(x):\n",
    "    \"\"\"\n",
    "    The derivative of our decaying sinusoid\n",
    "    \"\"\"\n",
    "    return -x/5 * np.exp(-x**2/10) * np.sin(2*x) + 2*np.exp(-x**2/10) * np.cos(2*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "x = np.linspace(0, 2*np.pi, 100)\n",
    "ax.plot(x, f(x), label=\"f(x)\")\n",
    "ax.plot(x, f_deriv(x), label=\"f'(x)\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks okay (?), how do we test it? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 1\n",
    "h0 = 0.5\n",
    "reduce_by = 2\n",
    "n_iter = 8\n",
    "\n",
    "# initiate with nans \n",
    "err1 = np.nan*np.zeros(n_iter)\n",
    "err2 = np.nan*np.zeros(n_iter)\n",
    "order1 = np.nan*np.zeros(n_iter)\n",
    "order2 = np.nan*np.zeros(n_iter)\n",
    "\n",
    "# compute function and derivative at x\n",
    "f_x = f(x)\n",
    "f_deriv_x = f_deriv(x)\n",
    "\n",
    "# create our vector of h-values \n",
    "h = h0 * (1/reduce_by)**(np.arange(n_iter))\n",
    "\n",
    "for i, hi in enumerate(h):\n",
    "    f_true = f(x+hi)\n",
    "    err1[i] = np.abs(f_true - f_x)\n",
    "    err2[i] = np.abs(f_true - (f_x + hi*f_deriv_x))\n",
    "    \n",
    "    if i > 0: \n",
    "        order1[i] = (err1[i-1] / err1[i])/reduce_by\n",
    "        order2[i] = (err2[i-1] / err2[i])/reduce_by\n",
    "    \n",
    "    print(f\"{hi:1.2e}  {err1[i]:1.2e}  {order1[i]:1.2f}  {err2[i]:1.2e}  {order2[i]:1.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "\n",
    "\n",
    "ax.loglog(h, err1, label=\"$\\mathcal{O}(h)$\");\n",
    "ax.loglog(h, err2, label=\"$\\mathcal{O}(h^2)$\");\n",
    "ax.invert_xaxis()\n",
    "ax.grid(\"both\")\n",
    "ax.legend()\n",
    "# ax.set_aspect(\"equal\")\n",
    "\n",
    "ax.set_xlabel(\"h\")\n",
    "ax.set_ylabel(\"error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Related: error handling \n",
    "_sometimes the coude should \"break\"_ \n",
    "\n",
    "Then it is important to give users (including yourself!) useful error messages to diagnose the problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(data, window_size):\n",
    "    \n",
    "    # checking types\n",
    "    if not isinstance(data, (np.ndarray, list)):\n",
    "        raise Exception(\n",
    "            f\"data must be a numpy.ndarray or a list. the input is type: {type(data)}\"\n",
    "        )\n",
    "    \n",
    "    if not isinstance(window_size, int):\n",
    "        raise Exception(\n",
    "            f\"window_size must be an int. The provided input type is {type(window_size)}\"\n",
    "        )\n",
    "    \n",
    "    # checking valid inputs\n",
    "    if window_size <= 0:\n",
    "        raise Exception(\n",
    "            f\"window_size must be strictly positive. The input value is {window_size}\"\n",
    "        )\n",
    "    \n",
    "    data = data.squeeze() # remove single-dimensional entries \n",
    "    if data.ndim > 1:\n",
    "        raise Exception(\n",
    "            f\"The current implementation only supports 1-dimensional arrays. The provided dimension is {data.ndim}\"\n",
    "        )\n",
    "        \n",
    "    average = np.full(data.size, np.nan)\n",
    "    half_window = window_size // 2\n",
    "    for i in range(half_window, data.size - half_window):\n",
    "        average[i] = np.mean(data[i - half_window: i + window_size-half_window])\n",
    "    return average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.r_[0, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.squeeze?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other ideas for testing \n",
    "\n",
    "## Examples as tests & consistency over time\n",
    "https://arxiv.org/pdf/1508.07231.pdf\n",
    "\n",
    "- save some result, check that you can still reproduce them if you make changes\n",
    "- visual checks, save and re-create figures\n",
    "\n",
    "## Realm of reasonable solutions\n",
    "- should the solution or inputs be strictly positive?\n",
    "    - throw random numbers at it, are the results physical\n",
    "    - what should your code do with non-sense\n",
    "- conserved quantities (e.g. conservation of energy)\n",
    "    - if not, then how does it behave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
